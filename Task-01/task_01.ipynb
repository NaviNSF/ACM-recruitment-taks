{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hLKrP_drn2V_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import RMSprop\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalization\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "VD5KcZD4qbww"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Flatten the input image dimensions to 1D\n",
        "model.add(layers.Flatten(input_shape=(32, 32, 3)))\n",
        "#adding layers\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo3yLpXrsrCt",
        "outputId": "7f104a96-f09e-4e37-87d5-438e5f9766ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1738890 (6.63 MB)\n",
            "Trainable params: 1738890 (6.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvESr9KHtG35",
        "outputId": "198acc67-f766-4df9-eecd-dd237cd47617"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 4.6955 - accuracy: 0.2143 - val_loss: 4.7411 - val_accuracy: 0.1516\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 4.6857 - accuracy: 0.2192 - val_loss: 4.7207 - val_accuracy: 0.2370\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 4.6530 - accuracy: 0.2427 - val_loss: 4.6316 - val_accuracy: 0.2529\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 4.6376 - accuracy: 0.2508 - val_loss: 4.6014 - val_accuracy: 0.2501\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 4.6135 - accuracy: 0.2559 - val_loss: 4.5818 - val_accuracy: 0.2490\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 4.7667 - accuracy: 0.1932 - val_loss: 4.8858 - val_accuracy: 0.1002\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 4.8176 - accuracy: 0.1608 - val_loss: 4.9472 - val_accuracy: 0.1033\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 4.8157 - accuracy: 0.1481 - val_loss: 4.8028 - val_accuracy: 0.1175\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 4.7603 - accuracy: 0.1636 - val_loss: 4.7088 - val_accuracy: 0.2074\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 4.6975 - accuracy: 0.2069 - val_loss: 4.6619 - val_accuracy: 0.2208\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 4.6642 - accuracy: 0.2285 - val_loss: 4.6448 - val_accuracy: 0.2254\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 4.7893 - accuracy: 0.1705 - val_loss: 4.8822 - val_accuracy: 0.1006\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 4.7517 - accuracy: 0.1876 - val_loss: 4.6736 - val_accuracy: 0.2313\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 4.6520 - accuracy: 0.2394 - val_loss: 4.6279 - val_accuracy: 0.2430\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 4.6199 - accuracy: 0.2523 - val_loss: 4.6008 - val_accuracy: 0.2503\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 30s 38ms/step - loss: 4.6145 - accuracy: 0.2559 - val_loss: 4.6373 - val_accuracy: 0.2446\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 4.6695 - accuracy: 0.2127 - val_loss: 4.6417 - val_accuracy: 0.2294\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 4.6411 - accuracy: 0.2546 - val_loss: 4.6046 - val_accuracy: 0.2648\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 4.6164 - accuracy: 0.2536 - val_loss: 4.5992 - val_accuracy: 0.2661\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 4.5890 - accuracy: 0.2682 - val_loss: 4.5706 - val_accuracy: 0.2681\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 4.5763 - accuracy: 0.2707 - val_loss: 4.5696 - val_accuracy: 0.2724\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 4.6638 - accuracy: 0.2241 - val_loss: 4.5909 - val_accuracy: 0.2576\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 4.5702 - accuracy: 0.2728 - val_loss: 4.5548 - val_accuracy: 0.2765\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 4.5579 - accuracy: 0.2777 - val_loss: 4.5520 - val_accuracy: 0.2738\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 4.5493 - accuracy: 0.2816 - val_loss: 4.5284 - val_accuracy: 0.2827\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 32s 41ms/step - loss: 3.8427 - accuracy: 0.2324 - val_loss: 3.3337 - val_accuracy: 0.2415\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 3.4911 - accuracy: 0.1435 - val_loss: 3.4300 - val_accuracy: 0.1556\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 3.3732 - accuracy: 0.2072 - val_loss: 3.3075 - val_accuracy: 0.2485\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 3.2859 - accuracy: 0.2568 - val_loss: 3.2532 - val_accuracy: 0.2577\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 3.3283 - accuracy: 0.2109 - val_loss: 3.3503 - val_accuracy: 0.1602\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 29s 38ms/step - loss: 3.3275 - accuracy: 0.1783 - val_loss: 3.2944 - val_accuracy: 0.2058\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 3.3101 - accuracy: 0.2177 - val_loss: 3.3917 - val_accuracy: 0.1792\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 3.2782 - accuracy: 0.2566 - val_loss: 3.2339 - val_accuracy: 0.2677\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 3.2357 - accuracy: 0.2740 - val_loss: 3.2236 - val_accuracy: 0.2787\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 3.2257 - accuracy: 0.2756 - val_loss: 3.2321 - val_accuracy: 0.2686\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 3.2108 - accuracy: 0.2840 - val_loss: 3.2033 - val_accuracy: 0.2890\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 3.2420 - accuracy: 0.2655 - val_loss: 3.2127 - val_accuracy: 0.2830\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 30s 39ms/step - loss: 3.2551 - accuracy: 0.2638 - val_loss: 3.2088 - val_accuracy: 0.2907\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 3.2216 - accuracy: 0.2840 - val_loss: 3.2002 - val_accuracy: 0.2909\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 3.2536 - accuracy: 0.2615 - val_loss: 3.2916 - val_accuracy: 0.2378\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 3.2433 - accuracy: 0.2660 - val_loss: 3.2073 - val_accuracy: 0.2719\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 3.1984 - accuracy: 0.2889 - val_loss: 3.1825 - val_accuracy: 0.2965\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 27s 34ms/step - loss: 3.2205 - accuracy: 0.2858 - val_loss: 3.2641 - val_accuracy: 0.2677\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 3.1746 - accuracy: 0.2931 - val_loss: 3.1556 - val_accuracy: 0.2985\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 3.1867 - accuracy: 0.2900 - val_loss: 3.1736 - val_accuracy: 0.2893\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 3.1982 - accuracy: 0.2833 - val_loss: 3.1571 - val_accuracy: 0.3022\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 3.1589 - accuracy: 0.3009 - val_loss: 3.2012 - val_accuracy: 0.2828\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 3.1477 - accuracy: 0.3064 - val_loss: 3.2093 - val_accuracy: 0.2705\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 3.1455 - accuracy: 0.3067 - val_loss: 3.1299 - val_accuracy: 0.3175\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 3.1202 - accuracy: 0.3191 - val_loss: 3.1254 - val_accuracy: 0.3170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2-Sg5ratK37",
        "outputId": "fa63da87-7dfa-42fb-914f-393dbc5031fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - loss: 3.1254 - accuracy: 0.3170 - 2s/epoch - 6ms/step\n",
            "Test accuracy: 0.31700000166893005\n"
          ]
        }
      ]
    }
  ]
}